{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn import cluster\n",
    "\n",
    "CHANNEL = \"blue\"\n",
    "\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "params.filterByInertia\n",
    "params.minInertiaRatio = 0.5\n",
    "\n",
    "#params.filterByColor = 1\n",
    "#params.blobColor = 1\n",
    "\n",
    "#params.filterByCircularity\n",
    "#params.maxCircularity = 0.8\n",
    "\n",
    "params.filterByArea\n",
    "params.minArea = 500\n",
    "#params.maxArea = 10000\n",
    "\n",
    "BLUR = 19\n",
    "maxVal = 200\n",
    "minVal = 150\n",
    "lowThresh = 80\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "def get_blobs(frame):\n",
    "    frame_blurred = cv2.medianBlur(frame, BLUR)\n",
    "    blobs = detector.detect(frame_blurred)\n",
    "    return blobs\n",
    "\n",
    "def get_dice_from_blobs(blobs):\n",
    "    # Get centroids of all blobs\n",
    "    X=[]\n",
    "    for b in blobs:\n",
    "        pos = b.pt\n",
    "        \n",
    "        if pos != None:\n",
    "            X.append(pos)\n",
    "            \n",
    "    X = np.asarray(X)\n",
    "    \n",
    "    if len(X) > 0:\n",
    "        pass\n",
    "    \n",
    "def overlay_info(frame, blobs):\n",
    "    for b in blobs:\n",
    "        pos = b.pt\n",
    "        r = b.size / 2\n",
    "        \n",
    "        cv2.circle(frame, (int(pos[0]), int(pos[1])),\n",
    "                  int(r), (255, 0, 0), 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def cropped(frame, blobs):\n",
    "    if len(blobs) == 1:\n",
    "        pos = blobs[0].pt\n",
    "        #r = int(blobs[0].size * 1.5)\n",
    "        r = 20\n",
    "        x = int(pos[0] - r/2)\n",
    "        y = int(pos[1] - r/2)\n",
    "        \n",
    "        cropped_frame = frame[y:y+r, x:x+r]\n",
    "\n",
    "        return cropped_frame\n",
    "    \n",
    "    \n",
    "#initialize a video feed\n",
    "cap = cv2.VideoCapture(3)\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    #size = frame.shape\n",
    "    #frame[12,:,:] = 0\n",
    "    #blobs = get_blobs(frame)\n",
    "    blurred = cv2.medianBlur(frame, BLUR)\n",
    "    #overlay_info(blurred, blobs)\n",
    "    #overlay_info(frame, blobs)\n",
    "    #edges = cv2.Canny(blurred,50,150)\n",
    "    grayscale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #cv2.imshow(\"blur\", blurred)\n",
    "    #cv2.imshow(\"frame\", frame)\n",
    "    \n",
    "    GBlur = cv2.GaussianBlur(grayscale, (15,15), 0)    \n",
    "    ret1, globalthreshold = cv2.threshold(GBlur,120,255,cv2.THRESH_BINARY)\n",
    "    #GBlur2 = cv2.GaussianBlur(globalthreshold, (25,25), 0)\n",
    "    M1Blur = cv2.medianBlur(globalthreshold, BLUR)\n",
    "    MBlur = cv2.medianBlur(M1Blur, BLUR)\n",
    "    \n",
    "    Gblobs = get_blobs(MBlur)\n",
    "\n",
    "    if len(Gblobs) == 1:\n",
    "        diceframe = cropped(frame, Gblobs)\n",
    "        cv2.imshow(\"Die\", diceframe)\n",
    "        graydice = cv2.cvtColor(diceframe, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow(\"Gray\", graydice)\n",
    "        ret2, diceThresh = cv2.threshold(graydice, lowThresh,255, cv2.THRESH_BINARY)\n",
    "        cv2.imshow(\"Dice threshold\", diceThresh)\n",
    "        \n",
    "        #edges = cv2.Canny(graydice, minVal, maxVal)\n",
    "        #cv2.imshow('edges', edges)\n",
    "         \n",
    "    #ret2, otsu = cv2.threshold(grayscale, 80,255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "   \n",
    "    #ret3, otsu2 = cv2.threshold(GBlur, 40, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "       \n",
    "    \n",
    "    #cv2.imshow(\"Global Threshold\", globalthreshold)\n",
    "    #cv2.imshow(\"Gaussian Blur\", GBlur)\n",
    "    cv2.imshow(\"Second Gaussian\", MBlur)\n",
    "\n",
    "    \n",
    "    \n",
    "    overlay_info(frame, Gblobs)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    \n",
    "    res = cv2.waitKey(1)\n",
    "    \n",
    "    if res & 0xFF == ord('n'):\n",
    "        lowThresh += 5\n",
    "        print(minVal) \n",
    "    if res & 0xFF == ord('m'):\n",
    "        maxVal += 5\n",
    "        print(maxVal)\n",
    "    \n",
    "    if res & 0xFF == ord('y'):\n",
    "        BLUR += 2 \n",
    "        print(\"Blur = \" + str(BLUR))\n",
    "    \n",
    "    if res & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "import pydot\n",
    "vgg = tf.keras.applications.VGG16(input_shape=[128, 128, 3], include_top=False, weights = 'imagenet')\n",
    "x = Flatten()(vgg.output)\n",
    "x = Dense(3, activation = 'sigmoid')(x)\n",
    "model1 = Model(vgg.input, x)\n",
    "model1.compile(loss='binary_crossentropy',optimizer = Adam(lr=0.001))\n",
    "\n",
    "plot_model(model1,\"firstmodel.png\",show_shapes=True, expand_nested=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a348b1dfa0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.patches import Circle\n",
    "\n",
    "def synthetic_gen(batch_size=64):\n",
    "    #enable generating infinite amount of batches\n",
    "    while True:\n",
    "        #generate black images in the wanted size\n",
    "        X = np.zeros((batch_size, 128, 128, 3))\n",
    "        Y = np.zeros((batch_size, 3))\n",
    "        # fill each image\n",
    "        for i in range(batch_size):\n",
    "            x = np.random.randint(8,120)\n",
    "            y = np.random.randint(8,120)\n",
    "            a = min(128 - max(x,y), min(x,y))\n",
    "            r = np.random.randint(4,a)\n",
    "            for x_i in range(128):\n",
    "                for y_i in range(128):\n",
    "                    if((x_i -x) **2) + ((y_i - y)**2) < r**2:\n",
    "                        X[i, x_i, y_i, :] = 1\n",
    "            Y[i,0] = (x-r)/128\n",
    "            Y[i,1] = (y-r)/128\n",
    "            Y[i,2] = 2*r / 128\n",
    "        yield X,Y\n",
    "\n",
    "# sanity check - plot the images\n",
    "x,y = next(synthetic_gen())\n",
    "plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhman\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/64 [===========>..................] - ETA: 13:39 - loss: 0.7825"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-49d07531682a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#needs steps per epoch since the generator is infinite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynthetic_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1845\u001b[0m                   \u001b[1;34m'will be removed in a future version. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[1;32m-> 1847\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1848\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#needs steps per epoch since the generator is infinite\n",
    "model1.fit_generator(synthetic_gen(), steps_per_epoch=EPOCH_SIZE, epochs = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
